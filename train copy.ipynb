{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from seqeval.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "from StringUtils import *\n",
    "from OCRUtils import *\n",
    "from model import * \n",
    "from DataLoader import *\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SROIEtrain = pd.read_pickle('./SROIE2019Train')\n",
    "SROIEtest = pd.read_pickle('./SROIE2019Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "347it [00:00, 1468.18it/s]\n"
     ]
    }
   ],
   "source": [
    "#image column for train set\n",
    "image_column = []\n",
    "SROIEtrainv1 = []\n",
    "\n",
    "\n",
    "for indx ,row in tqdm(SROIEtrain.iterrows()):\n",
    "    filename = row['filename']\n",
    "    folder_path = './SROIE2019/train/img'\n",
    "    image_path = os.path.join(folder_path, filename)\n",
    "    base_name, extension = os.path.splitext(image_path)\n",
    "\n",
    "    # Replace the extension with .jpg\n",
    "    image_path = base_name + '.jpg'\n",
    "    image = Image.open(image_path)\n",
    "    if image.size[0] < 2000:\n",
    "        image_column.append(image)\n",
    "        SROIEtrainv1.append(row)\n",
    "SROIEtrainv1 = pd.concat(SROIEtrainv1, axis=1).T\n",
    "SROIEtrainv1['image'] = image_column\n",
    "\n",
    "\n",
    "# # image column for test set\n",
    "image_column = []\n",
    "SROIEtestv1 = []\n",
    "\n",
    "\n",
    "for indx ,row in tqdm(SROIEentities.iterrows()):\n",
    "    filename = row['filename']\n",
    "    folder_path = './SROIE2019/test/img'\n",
    "    image_path = os.path.join(folder_path, filename)\n",
    "    base_name, extension = os.path.splitext(image_path)\n",
    "\n",
    "    # Replace the extension with .jpg\n",
    "    image_path = base_name + '.jpg'\n",
    "    image = Image.open(image_path)\n",
    "    if image.size[0] < 2000:\n",
    "        image_column.append(image)\n",
    "        SROIEtestv1.append(row)\n",
    "SROIEtestv1 = pd.concat(SROIEtestv1, axis=1).T\n",
    "SROIEtestv1['image'] = image_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "294it [00:01, 246.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# drop indexes for train set\n",
    "indexes_to_drop = []\n",
    "for indx ,row in tqdm(SROIEtrainv1.iterrows()):\n",
    "    image = row['image']\n",
    "    image_array = np.array(image)\n",
    "    ndim = image_array.ndim\n",
    "    if ndim < 3 :\n",
    "        print(indx, f'has only {ndim} dimensions ')\n",
    "        indexes_to_drop.append(indx)\n",
    "\n",
    "SROIEtrainv1.drop(index = indexes_to_drop, inplace= True)\n",
    "SROIEtrainv1 = SROIEtrainv1.reset_index()\n",
    "\n",
    "# # drop ondexes for test set\n",
    "indexes_to_drop = []\n",
    "for indx ,row in tqdm(SROIEtestv1.iterrows()):\n",
    "    image = row['image']\n",
    "    image_array = np.array(image)\n",
    "    ndim = image_array.ndim\n",
    "    if ndim < 3 :\n",
    "        print(indx, f'has only {ndim} dimensions ')\n",
    "        indexes_to_drop.append(indx)\n",
    "\n",
    "SROIEtestv1.drop(index = indexes_to_drop, inplace= True)\n",
    "SROIEtestv1 = SROIEtestv1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_boxes = []\n",
    "# for indx, row in SROIEtrain.iterrows():\n",
    "#     image = row['image']\n",
    "#     width, height = image.size \n",
    "\n",
    "#     boxes = row['boxes']\n",
    "\n",
    "#     normalized_boxes.append([normalize_box(box, width=width, height=height) for box in boxes])\n",
    "\n",
    "# SROIEtrain['nboxes'] = normalized_boxes\n",
    "\n",
    "\n",
    "\n",
    "# normalized_boxes = []\n",
    "# for indx, row in SROIEtestv1.iterrows():\n",
    "#     image = row['image']\n",
    "#     width, height = image.size \n",
    "\n",
    "#     boxes = row['boxes']\n",
    "\n",
    "#     normalized_boxes.append([normalize_box(box, width=width, height=height) for box in boxes])\n",
    "\n",
    "# SROIEtestv1['nboxes'] = normalized_boxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation : Pytorch DataLoader and training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutLMv3ImageProcessor\n",
    "batch_size = 8\n",
    "n_classes = 7\n",
    "\n",
    "feature_extractor = LayoutLMv3ImageProcessor(apply_ocr= False, do_normalize= True, do_resize= True)\n",
    "tokenizer = LayoutLMv3TokenizerFast.from_pretrained(\"microsoft/layoutlmv3-base\", max_length = 520)\n",
    "processor = LayoutLMv3Processor(feature_extractor,tokenizer)\n",
    "model = LayoutLMv3ForTokenClassification.from_pretrained(\n",
    "            \"microsoft/layoutlmv3-base\",\n",
    "            num_labels=n_classes\n",
    "        )\n",
    "\n",
    "train_dataset = TokenClassificationDataset(SROIEtrain, processor)\n",
    "eval_dataset = TokenClassificationDataset(SROIEtest, processor)\n",
    "\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(\n",
    "train_dataset,\n",
    "sampler=train_sampler,\n",
    "batch_size=batch_size,\n",
    "collate_fn=None,\n",
    ")\n",
    "\n",
    "eval_sampler = RandomSampler(eval_dataset)\n",
    "eval_dataloader = DataLoader(\n",
    "eval_dataset,\n",
    "sampler=eval_sampler,\n",
    "batch_size=batch_size,\n",
    "collate_fn=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters, arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 15\u001b[0m\n\u001b[0;32m      9\u001b[0m gradient_accumulation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m     10\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m optimizer_grouped_parameters \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     12\u001b[0m     {\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m     14\u001b[0m             p\n\u001b[1;32m---> 15\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m n, p \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mnamed_parameters()\n\u001b[0;32m     16\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(nd \u001b[38;5;129;01min\u001b[39;00m n \u001b[38;5;28;01mfor\u001b[39;00m nd \u001b[38;5;129;01min\u001b[39;00m no_decay)\n\u001b[0;32m     17\u001b[0m         ],\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m: weight_decay,\n\u001b[0;32m     19\u001b[0m     },\n\u001b[0;32m     20\u001b[0m     {\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m     22\u001b[0m             p\n\u001b[0;32m     23\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m n, p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_parameters()\n\u001b[0;32m     24\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(nd \u001b[38;5;129;01min\u001b[39;00m n \u001b[38;5;28;01mfor\u001b[39;00m nd \u001b[38;5;129;01min\u001b[39;00m no_decay)\n\u001b[0;32m     25\u001b[0m         ],\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m     27\u001b[0m     },\n\u001b[0;32m     28\u001b[0m ]\n\u001b[0;32m     29\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m AdamW(\n\u001b[0;32m     30\u001b[0m     optimizer_grouped_parameters, lr\u001b[38;5;241m=\u001b[39mlearning_rate, eps\u001b[38;5;241m=\u001b[39madam_epsilon\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     32\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m get_linear_schedule_with_warmup(\n\u001b[0;32m     33\u001b[0m     optimizer, num_warmup_steps\u001b[38;5;241m=\u001b[39mwarmup_steps, num_training_steps\u001b[38;5;241m=\u001b[39mt_total\n\u001b[0;32m     34\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "weight_decay = 1e-5\n",
    "learning_rate = 5e-5\n",
    "adam_epsilon = 1e-8\n",
    "warmup_steps = 10\n",
    "t_total = 3000\n",
    "num_train_epochs = 5\n",
    "gradient_accumulation_steps = 50\n",
    "device = torch.device('cuda')\n",
    "seed = 42\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p\n",
    "            for n, p in model.named_parameters()\n",
    "            if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": weight_decay,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p\n",
    "            for n, p in model.named_parameters()\n",
    "            if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "optimizer = AdamW(\n",
    "    optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon\n",
    ")\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train!\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "logger.info(\"  Num Epochs = %d\", num_train_epochs)\n",
    "logger.info(\n",
    "    \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
    "    batch_size\n",
    "    * gradient_accumulation_steps,\n",
    ")\n",
    "logger.info(\"  Gradient Accumulation steps = %d\", gradient_accumulation_steps)\n",
    "logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "global_step = 0\n",
    "tr_loss, logging_loss = 0.0, 0.0\n",
    "model.zero_grad()\n",
    "train_iterator = trange(\n",
    "    int(num_train_epochs), desc=\"Epoch\", disable=False\n",
    ")\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "set_seed(seed)  # Added here for reproductibility (even between python 2 and 3)\n",
    "for _ in train_iterator:\n",
    "    epoch_iterator = tqdm(\n",
    "        train_dataloader, desc=\"Iteration\", disable=False\n",
    "    )\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        model.train()\n",
    "        inputs = {\n",
    "            \"input_ids\": batch[0].to(device),\n",
    "            \"attention_mask\": batch[1].to(device),\n",
    "            \"labels\": batch[3].to(device),\n",
    "        }\n",
    "        if model_type in [\"layoutlm\"]:\n",
    "            inputs[\"bbox\"] = batch[4].to(device)\n",
    "        inputs[\"token_type_ids\"] = (\n",
    "            batch[2].to(device) if model_type in [\"bert\", \"layoutlm\"] else None\n",
    "        )  # RoBERTa don\"t use segment_ids\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        # model outputs are always tuple in pytorch-transformers (see doc)\n",
    "        loss = outputs[0]\n",
    "\n",
    "        if n_gpu > 1:\n",
    "            loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
    "        if gradient_accumulation_steps > 1:\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "\n",
    "        if fp16:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            if fp16:\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    amp.master_params(optimizer), max_grad_norm\n",
    "                )\n",
    "            else:\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    model.parameters(), max_grad_norm\n",
    "                )\n",
    "            optimizer.step()\n",
    "            scheduler.step()  # Update learning rate schedule\n",
    "            model.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "            if (\n",
    "                local_rank in [-1, 0]\n",
    "                and logging_steps > 0\n",
    "                and global_step % logging_steps == 0\n",
    "            ):\n",
    "                # Log metrics\n",
    "                if (\n",
    "                    local_rank in [-1, 0] and evaluate_during_training\n",
    "                ):  # Only evaluate when single GPU otherwise metrics may not average well\n",
    "                    results, _ = evaluate(\n",
    "                        args,\n",
    "                        model,\n",
    "                        tokenizer,\n",
    "                        labels,\n",
    "                        pad_token_label_id,\n",
    "                        mode=\"dev\",\n",
    "                    )\n",
    "                    for key, value in results.items():\n",
    "                        tb_writer.add_scalar(\n",
    "                            \"eval_{}\".format(key), value, global_step\n",
    "                        )\n",
    "                tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n",
    "                tb_writer.add_scalar(\n",
    "                    \"loss\",\n",
    "                    (tr_loss - logging_loss) / logging_steps,\n",
    "                    global_step,\n",
    "                )\n",
    "                logging_loss = tr_loss\n",
    "\n",
    "            if (\n",
    "                local_rank in [-1, 0]\n",
    "                and save_steps > 0\n",
    "                and global_step % save_steps == 0\n",
    "            ):\n",
    "                # Save model checkpoint\n",
    "                output_dir = os.path.join(\n",
    "                    output_dir, \"checkpoint-{}\".format(global_step)\n",
    "                )\n",
    "                if not os.path.exists(output_dir):\n",
    "                    os.makedirs(output_dir)\n",
    "                model_to_save = (\n",
    "                    model.module if hasattr(model, \"module\") else model\n",
    "                )  # Take care of distributed/parallel training\n",
    "                model_to_save.save_pretrained(output_dir)\n",
    "                tokenizer.save_pretrained(output_dir)\n",
    "                torch.save(args, os.path.join(output_dir, \"training_bin\"))\n",
    "                logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "\n",
    "        if max_steps > 0 and global_step > max_steps:\n",
    "            epoch_iterator.close()\n",
    "            break\n",
    "    if max_steps > 0 and global_step > max_steps:\n",
    "        train_iterator.close()\n",
    "        break\n",
    "\n",
    "if local_rank in [-1, 0]:\n",
    "    tb_writer.close()\n",
    "\n",
    "return global_step, tr_loss / global_step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
